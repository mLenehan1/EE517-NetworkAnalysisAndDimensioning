\subsection{Part 1}

This process is a Markov chain, as it meets the definition of a Markoc chain,
having both a discrete state space and is in discrete time.

The process is ergodic, as its properties are not time dependent. The mean value
is achieved through a sufficiently long sample (i.e. a large number of coin
flips).
